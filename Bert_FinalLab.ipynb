{"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0V7AY6zQ6C9l","executionInfo":{"status":"ok","timestamp":1655308326029,"user_tz":-120,"elapsed":14756,"user":{"displayName":"Paulina Campero","userId":"00406888576554037941"}},"outputId":"cf4c4a47-b2ef-4d37-965a-fb14ffd7e501"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 24.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.4\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28873,"status":"ok","timestamp":1655328205395,"user":{"displayName":"Klaus Ditterich Martin","userId":"12554408970924757965"},"user_tz":-120},"id":"4DVSD8xUb36E","outputId":"6db5ddea-5ff5-4a26-c995-6186203d674b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"," all_words.txt\t data_clean.csv\t\t 'IMDB Dataset.csv'   sorted_words.txt\n"," data_1\t\t data_no_stop_words.csv   inputs_ids.pt\n"]}],"source":["import torch\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import random\n","import pickle\n","import os\n","import nltk\n","from torch import nn\n","from torch.utils.data import DataLoader, TensorDataset\n","import tensorflow as tf \n","import string\n","import re\n","import pandas as pd \n","from collections import Counter\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from transformers import InputExample, InputFeatures\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('averaged_perceptron_tagger')\n","from nltk import word_tokenize, pos_tag\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","import nltk\n","nltk.download('omw-1.4')\n","drive.mount('/content/drive')\n","!ls '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final project/Data/'\n","myDrive = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final project/Data/'\n","results_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final project/Results/'"]},{"cell_type":"code","source":["data = pd.read_csv(f'{myDrive}data_clean.csv')\n","file1 = open(f'{myDrive}all_words.txt', 'r')\n","file2 = open(f'{myDrive}sorted_words.txt', 'r')\n","all_words = file1.read().splitlines()\n","count_words = Counter(all_words)\n","sorted_words=count_words.most_common(len(all_words))\n","vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n"],"metadata":{"id":"WCHD8BT3NEk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvfBrWEkg2NK"},"outputs":[],"source":["data.sentiment = [0 if each == \"negative\" else 1 for each in data.sentiment]"]},{"cell_type":"code","source":["def encode_review(review):\n","  encoded_review=list()\n","  words = review.split(' ')\n","  for word in words:\n","    encoded_review.append(vocab_to_int[word])\n","\n","  return encoded_review"],"metadata":{"id":"6Ds4jKunxtMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['review'] = data.apply(lambda row: encode_review(row['review']), axis = 1)\n","data['review_length'] = data.apply(lambda row: len(row['review']), axis = 1)"],"metadata":{"id":"fFN9zwKVxbur"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The sequence length of our sentences should be the same. Thus, we will calculate the average length of reviews (in words) and truncate or pad each review to have such amount of words. "],"metadata":{"id":"4CpIR3VRClTm"}},{"cell_type":"code","source":["sequence_length = int(sum(list(data['review_length']))/data.shape[0]) # average length\n","sequence_length_max = max(list(data['review_length']))\n","print(sequence_length)\n","\n","def truncate_or_pad(review):\n","  num_words = len(review)\n","  if num_words<sequence_length:\n","    zeros = list(np.zeros(sequence_length-num_words))\n","    new = zeros+review\n","  else:\n","    new = review[:sequence_length]\n","\n","  return new\n","\n","def pad(review):\n","  num_words = len(review)\n","  new = review\n","  if num_words<sequence_length_max:\n","    zeros = list(np.zeros(sequence_length_max-num_words))\n","    new = zeros+review\n","  return new\n","\n","#test = truncate_or_pad(data.review[0])\n","data_pad = data.copy()\n","data['review'] = data.apply(lambda row: truncate_or_pad(row['review']), axis = 1)\n","data_pad['review'] = data_pad.apply(lambda row: pad(row['review']), axis = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6-idfop8vyj","executionInfo":{"status":"ok","timestamp":1655328401703,"user_tz":-120,"elapsed":8607,"user":{"displayName":"Klaus Ditterich Martin","userId":"12554408970924757965"}},"outputId":"e172e117-adc3-4424-ca76-f6514f80346f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["118\n"]}]},{"cell_type":"code","source":["'''data_matrix = np.zeros((data.shape[0], sequence_length), dtype=int)\n","for i in range(data.shape[0]):\n","  data_matrix[i, :] = np.array(data.review[i])\n","print(data_matrix[0:15, :])\n","print(data.review_length[2])'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZ76eJsLA_gq","executionInfo":{"status":"ok","timestamp":1655310381119,"user_tz":-120,"elapsed":1267,"user":{"displayName":"Paulina Campero","userId":"00406888576554037941"}},"outputId":"ed081365-6f40-402f-f4a4-b3f168509053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[    3  1020   326 ...    23  1356    12]\n"," [    0     0     0 ...  1816  1676    19]\n"," [    0     0     0 ...    13     6   122]\n"," ...\n"," [ 3771   105   110 ...   631     2   546]\n"," [    0     0     0 ...    23    13   341]\n"," [    0     0     0 ...  1104 11136  6458]]\n","85\n"]}]},{"cell_type":"code","source":["data_matrix_pad = np.zeros((data_pad.shape[0], sequence_length_max), dtype=int)\n","for i in range(data_pad.shape[0]):\n","  data_matrix_pad[i, :] = np.array(data_pad.review[i])\n","print(data_matrix_pad[0:15, :])\n","print(data_pad.review_length[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jOW5LjHw4u8","executionInfo":{"status":"ok","timestamp":1655328411567,"user_tz":-120,"elapsed":8526,"user":{"displayName":"Klaus Ditterich Martin","userId":"12554408970924757965"}},"outputId":"1cb173c6-c5b1-44ed-c2a2-ff2a5bb5db1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[    0     0     0 ...   469  3431   323]\n"," [    0     0     0 ...  1816  1676    19]\n"," [    0     0     0 ...    13     6   122]\n"," ...\n"," [    0     0     0 ...   179    90   160]\n"," [    0     0     0 ...    23    13   341]\n"," [    0     0     0 ...  1104 11136  6458]]\n","85\n"]}]},{"cell_type":"markdown","source":["# Bert Word Embedding and model "],"metadata":{"id":"1Ks37N3VIPTG"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","tf_batch = tokenizer(list(data2['review']), max_length=128, padding=True, truncation=True, return_tensors='tf')"],"metadata":{"id":"K8fIemz0EmP_","executionInfo":{"status":"ok","timestamp":1655308771551,"user_tz":-120,"elapsed":192673,"user":{"displayName":"Paulina Campero","userId":"00406888576554037941"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["57bada409b454a97b68cd37f70e361b8","0706eec68755439e975f1a52fed078b4","0ede0172595740f2af515f374bc13282","3aaa0457f5044abf807cc21878195878","f03d3d66f41447c4a8f304d2eecba727","599f08789d034804889f906734a70cb7","93dc971163b04af6b73bd2d085cf417a","da2a28979b5b408f9c888cd333fc7b5a","2dc804d3f8334d07b2b4a654807ff5cf","d4862594a57c4c2f8734f16f11e20727","d75e5dc7fed348dca52771b6f4d803a4","00d460d92c174bb08cf274e633b59aaf","29af2b2b301c46b0b2aca11962f8f01f","8229dce2455f4e94bfffddd207d0f448","b528879552cd4a5a9bcb381586d603e0","ee62e19e756e46d1a97162d71c7af0f9","baec960df77744dcac74c73059b959eb","14d9229637504493b1e595d466f6a563","ecc8881b90a14a07a41f3254b3bee1df","1920a5662df74d2a8b8e9a0fd12b3be7","c157267872224abb89e5c9d3092da96b","462db2e511994f3899a649d2b4cd1911","c6c55331cca442b1b2d6a026770e5054","093f8d9df6d94dfb84b6665d5457bfb6","9ebddbe15db2425c899e5f5c9d523fa4","585ad17e744c43df83a7525ae6cf35d0","bec4c85acceb4a96af8028dcd2b80411","17c48127a6714d279915e48fd611deab","befd9f5b3bde41ca96c36ad86abec0b5","70346a6539164863b180e1002defb40f","682a165b1304472ba313aa123ec07182","d06cdf6989cb4e15b1d30e03488a1583","398c10e4fc9048958d8b51eb4acc8282"]},"outputId":"90134dc5-dd4d-41a8-9fcb-ee8f6ce3f6f2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bada409b454a97b68cd37f70e361b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d460d92c174bb08cf274e633b59aaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c55331cca442b1b2d6a026770e5054"}},"metadata":{}}]},{"cell_type":"code","source":["def tokenize(review):\n","  review = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(review))\n","  return review"],"metadata":{"id":"IdsZtVRvNx-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2['review'] = data2.apply(lambda row: tokenize(row['review']), axis = 1)"],"metadata":{"id":"tBfsj19BNj0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs_ids = []\n","attention_masks = []\n","for review in data2['review']:\n","    encoded_dict = tokenizer.encode_plus(\n","                          review, \n","                          add_special_tokens = True, \n","                          max_length = sequence_length_max, \n","                          pad_to_max_length = True, \n","                          return_attention_mask = True,)\n","\n","    inputs_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","inputs_ids = tf.convert_to_tensor(inputs_ids)\n","attention_masks = tf.convert_to_tensor(attention_masks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nc2FGdqBJCW","executionInfo":{"status":"ok","timestamp":1655309442945,"user_tz":-120,"elapsed":54554,"user":{"displayName":"Paulina Campero","userId":"00406888576554037941"}},"outputId":"347e89a3-6042-4edd-f854-980c3d5f52cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["def mask_inputs_for_bert(reviews, sequence_length_max, inputs_ids, attention_masks):\n","  for review in reviews:\n","    encoded_dict = tokenizer.encode_plus(\n","                          review, \n","                          add_special_tokens = True, \n","                          max_length = sequence_length_max, \n","                          pad_to_max_length = True, \n","                          return_attention_mask = True,)\n","\n","    inputs_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  inputs_ids = tf.convert_to_tensor(inputs_ids)\n","  attention_masks = tf.convert_to_tensor(attention_masks)\n","  return inputs_ids, attention_masks"],"metadata":{"id":"vCh6PnU4ROdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inputs_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0uBJLidCWFX","executionInfo":{"status":"ok","timestamp":1655309509530,"user_tz":-120,"elapsed":1103,"user":{"displayName":"Paulina Campero","userId":"00406888576554037941"}},"outputId":"7c1c138b-68e9-4b40-e46e-22121ce2ad59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[  101  2028 12027 ...     0     0     0]\n"," [  101  6919  2210 ...     0     0     0]\n"," [  101  2228  6919 ...     0     0     0]\n"," ...\n"," [  101  3234  4036 ...     0     0     0]\n"," [  101  2175 21090 ...     0     0     0]\n"," [  101  2028  5987 ...     0     0     0]], shape=(50000, 1418), dtype=int32)\n"]}]},{"cell_type":"code","source":["torch.save(inputs_ids, f'{myDrive}inputs_ids.pt') "],"metadata":{"id":"_xJ_NBaNCxxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs_ids = torch.load(f'{myDrive}inputs_ids.pt')"],"metadata":{"id":"0th0b16GDSu8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create and train LSTM model "],"metadata":{"id":"AWkYsBs8Gc9z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"epUZVsoEeImz"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(data_matrix_pad, list(data_pad.sentiment), test_size=0.3)"]},{"cell_type":"code","source":["train_data=TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","test_data=TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))"],"metadata":{"id":"xTR1CMCrGiXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=50\n","train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"lGngfttiHFSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" \n","class SentimentalLSTM(nn.Module):\n","    \"\"\"\n","    The RNN model that will be used to perform Sentiment analysis.\n","    \"\"\"\n","    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n","        \"\"\"\n","        Initialize the model by setting up the layers\n","        \"\"\"\n","        super().__init__()\n","        self.output_size=output_size\n","        self.n_layers=n_layers\n","        self.hidden_dim=hidden_dim\n","        \n","        #Embedding and LSTM layers\n","        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight = nn.Parameter(torch.tensor(inputs_ids.numpy(),dtype=torch.float32))\n","\n","        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n","        \n","        #dropout layer\n","        self.dropout=nn.Dropout(0.5)\n","        \n","        #Linear and sigmoid layer\n","        self.fc1=nn.Linear(hidden_dim, 64)\n","        self.fc2=nn.Linear(64, 16)\n","        self.fc3=nn.Linear(16,output_size)\n","        self.sigmoid=nn.Sigmoid()\n","        \n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size=x.size()\n","        \n","        #Embadding and LSTM output\n","        embedd=self.embedding(x)\n","        lstm_out, hidden=self.lstm(embedd, hidden)\n","        \n","        #stack up the lstm output\n","        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n","        \n","        #dropout and fully connected layers\n","        out=self.dropout(lstm_out)\n","        out=self.fc1(out)\n","        out=self.dropout(out)\n","        out=self.fc2(out)\n","        out=self.dropout(out)\n","        out=self.fc3(out)\n","        sig_out=self.sigmoid(out)\n","        \n","        sig_out=sig_out.view(batch_size, -1)\n","        sig_out=sig_out[:, -1]\n","        \n","        return sig_out, hidden\n","    \n","    def init_hidden(self, batch_size):\n","        \"\"\"Initialize Hidden STATE\"\"\"\n","        # Create two new sensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        \n","        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n","        return hidden"],"metadata":{"id":"hD9Ohl9EdJQq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pny7945jbdtW"},"outputs":[],"source":["def train_loop(model, model_name = 'model.ckpt', device = 'cuda'):\n","    model.train()\n","    total_step = len(train_loader)\n","    losses_list = []\n","    criterion = nn.BCELoss()\n","\n","    for epoch in range(num_epochs):\n","        loss_avg = 0\n","        h = net.init_hidden(batch_size)\n","        nBatches = 0\n","        # TRAINING LOOP\n","        for i, (review, sentiment) in enumerate(train_loader):\n","            review = review.type(torch.LongTensor).to(device)\n","            sentiment = sentiment.to(device)\n","\n","            h = tuple([each.data for each in h])\n","            net.zero_grad()\n","\n","            # Forward pass\n","            outputs,h = model(review, h)\n","            # Calculate CE_loss\n","            loss = criterion(outputs, sentiment)\n","\n","            # Backpropagate\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_avg += loss.cpu().item()\n","            nBatches+=1\n","            if (i+1) % 200 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        losses_list.append(loss_avg / nBatches)\n","        torch.save(model.state_dict(), results_path+model_name)\n"]},{"cell_type":"code","source":["#Load and test function\n","def load_and_test(model, device='cuda', model_name = 'model.ckpt'):\n","  model.load_state_dict(torch.load(results_path+model_name))\n","  criterion = nn.BCELoss()\n","  h = net.init_hidden(batch_size)\n","  # Test the model\n","  model.eval() # Set the model in evaluation mode\n","\n","  # Compute testing accuracy\n","  with torch.no_grad():\n","      correct = 0\n","      total = 0\n","      for review, sentiment in test_loader:\n","          h = tuple([each.data for each in h])\n","\n","          review = review.type(torch.LongTensor).to(device)\n","          sentiment = sentiment.to(device)\n","          # get network predictions\n","          outputs, h = model(review, h)\n","\n","          # get predicted class\n","          predicted = torch.round(outputs)\n","          # compare with the ground-truth\n","          total += sentiment.size(0)\n","          correct += (predicted == sentiment).sum().item()\n","\n","      print('Test Accuracy of the model: {} %'.format(100 * correct / total))"],"metadata":{"id":"ECBEhZiXX2pd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''# Instantiate the model w/ hyperparams\n","vocab_size = word_embedding.shape[0]\n","output_size = 1\n","embedding_dim = word_embedding.shape[1]\n","hidden_dim = 128\n","n_layers = 2\n","\n","#net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","#net = net.cuda()\n","#print(net)'''"],"metadata":{"id":"n7jXB-7Gm_St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate the model w/ hyperparams\n","vocab_size = inputs_ids.shape[0]\n","output_size = 1\n","embedding_dim = inputs_ids.shape[1]\n","hidden_dim = 128\n","n_layers = 2\n","num_epochs = 6\n","net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).cuda()\n","\n","optimizer = torch.optim.Adam(net.parameters(),lr = 0.001)\n","\n","# Device configuration (choose GPU if it is available )\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","train_loop(net, model_name = 'model_4.ckpt')\n","load_and_test(net,  model_name = 'model_4.ckpt')\n"],"metadata":{"id":"MrODAhSVcwFQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AECrU3kabgbE"},"outputs":[],"source":["num_epochs = 6\n","for lr_i in [0.001, 0.0005, 0.002]:\n","  net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","  net = net.cuda()\n","  optimizer = torch.optim.Adam(net.parameters(),lr = lr_i)\n","\n","  # Device configuration (choose GPU if it is available )\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","  train_loop(net, model_name = 'model_4.ckpt')\n","  load_and_test(net,  model_name = 'model_4.ckpt')"]},{"cell_type":"code","source":["for lr_i in [0.001, 0.01, 0.05, 0.06]:\n","  net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","  net = net.cuda()\n","  optimizer = torch.optim.SGD(net.parameters(), lr=lr_i, momentum=0.9)\n","\n","  # Device configuration (choose GPU if it is available )\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","  train_loop(net, model_name = 'model_4.ckpt')\n","  load_and_test(net,  model_name = 'model_4.ckpt')"],"metadata":{"id":"5DaKKJRt0peq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for mom in [0.8, 0.85, 0.89, 0.95]:\n","  net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","  net = net.cuda()\n","  optimizer = torch.optim.SGD(net.parameters(), lr=0.05, momentum=mom)\n","\n","  # Device configuration (choose GPU if it is available )\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","  train_loop(net, model_name = 'model_4.ckpt')\n","  load_and_test(net,  model_name = 'model_4.ckpt')"],"metadata":{"id":"YIdEWywu0-e2"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Bert_FinalLab.ipynb","provenance":[{"file_id":"1srwmU1hsFCKNLjDdnzYKAXw1aES13DXR","timestamp":1655305603790}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"57bada409b454a97b68cd37f70e361b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0706eec68755439e975f1a52fed078b4","IPY_MODEL_0ede0172595740f2af515f374bc13282","IPY_MODEL_3aaa0457f5044abf807cc21878195878"],"layout":"IPY_MODEL_f03d3d66f41447c4a8f304d2eecba727"}},"0706eec68755439e975f1a52fed078b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_599f08789d034804889f906734a70cb7","placeholder":"​","style":"IPY_MODEL_93dc971163b04af6b73bd2d085cf417a","value":"Downloading: 100%"}},"0ede0172595740f2af515f374bc13282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2a28979b5b408f9c888cd333fc7b5a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dc804d3f8334d07b2b4a654807ff5cf","value":231508}},"3aaa0457f5044abf807cc21878195878":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4862594a57c4c2f8734f16f11e20727","placeholder":"​","style":"IPY_MODEL_d75e5dc7fed348dca52771b6f4d803a4","value":" 226k/226k [00:00&lt;00:00, 268kB/s]"}},"f03d3d66f41447c4a8f304d2eecba727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"599f08789d034804889f906734a70cb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93dc971163b04af6b73bd2d085cf417a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da2a28979b5b408f9c888cd333fc7b5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc804d3f8334d07b2b4a654807ff5cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4862594a57c4c2f8734f16f11e20727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d75e5dc7fed348dca52771b6f4d803a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00d460d92c174bb08cf274e633b59aaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29af2b2b301c46b0b2aca11962f8f01f","IPY_MODEL_8229dce2455f4e94bfffddd207d0f448","IPY_MODEL_b528879552cd4a5a9bcb381586d603e0"],"layout":"IPY_MODEL_ee62e19e756e46d1a97162d71c7af0f9"}},"29af2b2b301c46b0b2aca11962f8f01f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baec960df77744dcac74c73059b959eb","placeholder":"​","style":"IPY_MODEL_14d9229637504493b1e595d466f6a563","value":"Downloading: 100%"}},"8229dce2455f4e94bfffddd207d0f448":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc8881b90a14a07a41f3254b3bee1df","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1920a5662df74d2a8b8e9a0fd12b3be7","value":28}},"b528879552cd4a5a9bcb381586d603e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c157267872224abb89e5c9d3092da96b","placeholder":"​","style":"IPY_MODEL_462db2e511994f3899a649d2b4cd1911","value":" 28.0/28.0 [00:00&lt;00:00, 765B/s]"}},"ee62e19e756e46d1a97162d71c7af0f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baec960df77744dcac74c73059b959eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14d9229637504493b1e595d466f6a563":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc8881b90a14a07a41f3254b3bee1df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1920a5662df74d2a8b8e9a0fd12b3be7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c157267872224abb89e5c9d3092da96b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462db2e511994f3899a649d2b4cd1911":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6c55331cca442b1b2d6a026770e5054":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_093f8d9df6d94dfb84b6665d5457bfb6","IPY_MODEL_9ebddbe15db2425c899e5f5c9d523fa4","IPY_MODEL_585ad17e744c43df83a7525ae6cf35d0"],"layout":"IPY_MODEL_bec4c85acceb4a96af8028dcd2b80411"}},"093f8d9df6d94dfb84b6665d5457bfb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17c48127a6714d279915e48fd611deab","placeholder":"​","style":"IPY_MODEL_befd9f5b3bde41ca96c36ad86abec0b5","value":"Downloading: 100%"}},"9ebddbe15db2425c899e5f5c9d523fa4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70346a6539164863b180e1002defb40f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_682a165b1304472ba313aa123ec07182","value":570}},"585ad17e744c43df83a7525ae6cf35d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06cdf6989cb4e15b1d30e03488a1583","placeholder":"​","style":"IPY_MODEL_398c10e4fc9048958d8b51eb4acc8282","value":" 570/570 [00:00&lt;00:00, 11.2kB/s]"}},"bec4c85acceb4a96af8028dcd2b80411":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c48127a6714d279915e48fd611deab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"befd9f5b3bde41ca96c36ad86abec0b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70346a6539164863b180e1002defb40f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682a165b1304472ba313aa123ec07182":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d06cdf6989cb4e15b1d30e03488a1583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"398c10e4fc9048958d8b51eb4acc8282":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}